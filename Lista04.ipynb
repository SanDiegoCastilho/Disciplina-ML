{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpl_train(neurons, features, labels):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(neurons), activation = 'relu', batch_size=100, momentum=0.9, max_iter=1500)\n",
    "    model.fit(features, labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, features, labels):\n",
    "    return model.score(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_cross_validate(neurons, features, labels):\n",
    "    kf = KFold(n_splits=4)\n",
    "    kf.get_n_splits(features)\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model = mlp_train(neurons, X_train, y_train)\n",
    "        accuracy = test(model, X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_minmax = min_max_scaler.fit_transform(X_train\n",
    "#Leitura dos dados\n",
    "data_set = np.genfromtxt('vowel.csv', delimiter = ',')\n",
    "\n",
    "X = data_set[:, :-1]\n",
    "y = data_set[:, -1]\n",
    "\n",
    "#P/ Normalização\n",
    "scaler = StandardScaler()\n",
    "                                              \n",
    "#Cria o primeiro subconjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#scaler.fit(X_train)  \n",
    "#X_train = scaler.transform(X_train)  \n",
    "#X_test = scaler.transform(X_test)                                         \n",
    "                                              \n",
    "#Cria um subconjunto de validação a partir dos dados de treino\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "#X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(594, 10)\n",
      "(594,)\n"
     ]
    }
   ],
   "source": [
    "# 80% para treino\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 10)\n",
      "(198,)\n"
     ]
    }
   ],
   "source": [
    "# 20% teste\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 10)\n",
      "(198,)\n"
     ]
    }
   ],
   "source": [
    "#20% validação\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\San Diego\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525252525252525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\San Diego\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8535353535353535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\San Diego\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\San Diego\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9343434343434344\n",
      "0.9343434343434344\n",
      "0.9494949494949495\n"
     ]
    }
   ],
   "source": [
    "for n in [8,16,32,64,128,256]:\n",
    "    model = mpl_train(n, X_train, y_train)\n",
    "    ac = test(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8838383838383839"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\San Diego\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(15,), batch_size=20, momentum=0.9, max_iter=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 8., 1., 6., 1., 1., 0., 2., 0., 1., 1., 8., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 5., 1., 1., 0., 8., 1., 0., 1., 8., 1., 1., 0., 1.,\n",
       "       0., 0., 5., 1., 0., 1., 1., 1., 6., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       6., 1., 6., 1., 1., 0., 1., 1., 1., 6., 0., 0., 0., 8., 1., 0., 6.,\n",
       "       1., 0., 1., 6., 2., 0., 1., 1., 0., 2., 0., 6., 0., 8., 6., 1., 0.,\n",
       "       0., 0., 5., 1., 0., 6., 5., 5., 1., 6., 1., 0., 0., 1., 0., 1., 5.,\n",
       "       6., 0., 6., 0., 8., 0., 0., 0., 7., 0., 6., 6., 8., 1., 5., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 8., 0., 5., 6., 1., 1., 6., 0.,\n",
       "       8., 0., 0., 0., 6., 6., 6., 6., 1., 1., 2., 6., 5., 1., 0., 6., 1.,\n",
       "       1., 6., 6., 1., 5., 6., 0., 6., 0., 0., 6., 0., 6., 6., 6., 0., 0.,\n",
       "       1., 0., 6., 1., 0., 2., 0., 0., 0., 1., 2., 6., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 8., 8., 0., 1., 1., 6., 0., 6.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_val)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7222222222222222"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20707070707070707"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
